{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2321f417",
      "metadata": {
        "id": "2321f417"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1e7ctPi8O3bTQoLZaO9ZZjwGr2r8Z93RS\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d4654a1",
      "metadata": {
        "id": "8d4654a1"
      },
      "source": [
        "# Taller 3\n",
        "---\n",
        "\n",
        "En este taller se evaluarán las habilidades adquiridas en _embeddings_ a partir del conjunto de datos de Kaggle: [Spanish Poetry Dataset](https://www.kaggle.com/datasets/andreamorgar/spanish-poetry-dataset), el cual contiene poemas en español.\n",
        "\n",
        "En este caso, usted deberá limpiar el conjunto de datos, calcular algunas representaciones, estimar algunas métricas y generar visualizaciones de los datos. Comenzamos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "881ee81e",
      "metadata": {
        "id": "881ee81e"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b34d12c",
      "metadata": {
        "id": "0b34d12c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Counter\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from unidecode import unidecode\n",
        "from IPython.display import display\n",
        "plt.style.use(\"ggplot\")\n",
        "spacy.cli.download(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501ad44b",
      "metadata": {
        "id": "501ad44b"
      },
      "source": [
        "Comenzamos cargando el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mindlab-unal/mlds4-case-study/refs/heads/main/dataset/poems.csv"
      ],
      "metadata": {
        "id": "6Lo1ZU22zSco"
      },
      "id": "6Lo1ZU22zSco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55d7213b",
      "metadata": {
        "id": "55d7213b"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "df = pd.read_csv(\"poems.csv\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f27a102",
      "metadata": {
        "id": "7f27a102"
      },
      "source": [
        "Este conjunto de datos contiene dos columnas:\n",
        "\n",
        "- `author`: autor del poema.\n",
        "- `content`: poema.\n",
        "- `title`: titulo del poema.\n",
        "\n",
        "Este corpus está conformado por `5133` documentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63576fd4",
      "metadata": {
        "id": "63576fd4"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78450dd5",
      "metadata": {
        "id": "78450dd5"
      },
      "source": [
        "## **1. Preprocesamiento**\n",
        "---\n",
        "\n",
        "En esta etapa, deberás preprocesar los documentos siguiendo estos pasos:\n",
        "\n",
        "1. Convertir en **minúsculas**.\n",
        "2. Eliminar **acentos**.\n",
        "3. Eliminar **todos los caracteres que no sean letras minúsculas**.\n",
        "4. **Eliminar espacios duplicado**s.\n",
        "5. **Filtrar stopwords** y palabras de tres **(3) o menos letras**.\n",
        "6. **Eliminar caracteres vacíos** al inicio y final de cada texto.\n",
        "\n",
        "Puede usar el siguiente _Pipeline_ de `spacy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f813640c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f813640c"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\n",
        "        \"es_core_news_sm\",\n",
        "        exclude=[\n",
        "            \"tok2vec\",\n",
        "            \"morphologizer\",\n",
        "            \"parser\",\n",
        "            \"senter\",\n",
        "            \"attribute_ruler\",\n",
        "            \"lemmatizer\",\n",
        "            \"ner\"\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf89b99d",
      "metadata": {
        "id": "cf89b99d"
      },
      "source": [
        "A continuación, deberás implementar la función `preprocess` ue tomará como entrada un texto crudo y un _Pipeline_ de `spacy` para retornar el texto preprocesado.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `text` *(str)*: texto crudo.\n",
        "- `nlp`*(spaCy pipeline)*: _Pipeline_ de `spacy`.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `preprocess_text` *(str)*: texto preprocesado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942de1ef",
      "metadata": {
        "id": "942de1ef"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede usar `unidecode` para eliminar acentos.\n",
        "- Debe construir expresiones regulares con `re` para eliminar caracteres especiales.\n",
        "- El _Pipeline_ de `spacy` debe usarse exclusivamente para eliminar _stopwords_.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85327a8a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "85327a8a"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA preprocess:\n",
        "\n",
        "def preprocess(text, nlp):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    preprocess_text = ...\n",
        "    return preprocess_text\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d73c32",
      "metadata": {
        "id": "c5d73c32"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "text = preprocess(df.content.iloc[0], nlp)\n",
        "display(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b59b694",
      "metadata": {
        "id": "0b59b694"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el primer documento pre-procesado:\n",
        "\n",
        "```python\n",
        "❱ display(text)\n",
        "'parque confuso languidas brisas cielo sahuma cipres huso devana ovillo bruma telar luna tiende plata urdimbre abandona rada lugubre corsario suena timbre vecindario horizonte malva argentina curva frente calva luna inclina vago nacar disemina valva madreperla flor agua marina brillo lobrego frasco adquiere noche enorme penasco quedandose inmensamente forma reloj accesorio tela vida siniestro pespunte flota noche blancor mortuorio benzoica insispidez sanatorio transeunte silueta purgatorio emocion prosaica suena lejos canto lugubre alarde hombre desgraciado arde calor negro jamaica reina espiritu subconsciencie arcaica miedo horizonte abstracto hundese luna lugubre abandono tinieblas palpan tacto helado sombrio mono lunares huellas azar eternidad desdicha orion juega ficha problematico domino estrellas frescor nocturno triunfa amoroso empeno domina frente peso taciturno negro racimo sueno fugaz desvario embargan sonadas visiones vacilan constelaciones sueno formado aroma estio flota ant...'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1012f4",
      "metadata": {
        "id": "eb1012f4"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "text = preprocess(df.content.iloc[1], nlp)\n",
        "display(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3166a8",
      "metadata": {
        "id": "ce3166a8"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el segundo documento pre-procesado:\n",
        "\n",
        "```python\n",
        "❱ display(text)\n",
        "'velas vendre ladron llegar sepas hora estate alerta vigila accion recibido escuchado memora nombre vivo posees muerto perfectas dios encontrado obras consolidalas morir arrepientes obras estrellas diestra espiritus dios unico arde vestira venciere blancas vestiduras libro vida nombre santa muestra jamas borrar dire alturas vendre ladron vendre ladron improviso oscuras'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d143e13",
      "metadata": {
        "id": "8d143e13"
      },
      "source": [
        "## **2. Bolsa de palabras**\n",
        "---\n",
        "En este apartado, extraerás una representación de **bolsa de palabras** (*Bag of Words*), basada en conteos. Esta representación utilizará únicamente los **2000 tokens más comunes** del corpus.  \n",
        "\n",
        "Para ello, deberás implementar la función **`bow`**, que recibirá como entrada el corpus preprocesado y devolverá un arreglo de `numpy` con los resultados.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `preprocess_corpus` *(str)*: corpus con los textos preprocesados.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `X` *(numpy array)*: Representación de bolsa de palabras basada en conteos.\n",
        "- `vect` *(sklearn vectorizer)*: Vectorizador de `sklearn` entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d46981e",
      "metadata": {
        "id": "4d46981e"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde filtrar los 2000 términos más frecuentes con el parámetro `max_features`.\n",
        "- Recuerde convertir el resultado a un arreglo de `numpy` con el método `toarray`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a135283",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "7a135283"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA bow:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def bow(preprocess_corpus):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    vect = ...\n",
        "    X = ...\n",
        "    return X, vect\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d220e555",
      "metadata": {
        "id": "d220e555"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "display(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1d47ed8",
      "metadata": {
        "id": "c1d47ed8"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso, debería obtener el tamaño del arreglo:\n",
        "\n",
        "```python\n",
        "❱ display(X.shape)\n",
        "(5133, 2000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac971f0",
      "metadata": {
        "id": "6ac971f0"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(vect.get_feature_names_out()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95dbcb5c",
      "metadata": {
        "id": "95dbcb5c"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso debería obtener las primeras 10 palabras del vocabulario:\n",
        "\n",
        "```python\n",
        "❱ display(vect.get_feature_names_out()[:10])\n",
        "array(['abajo', 'abandonado', 'abandono', 'abeja', 'abejas', 'abierta',\n",
        "       'abiertas', 'abierto', 'abiertos', 'abismo'], dtype=object)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6fb69c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "ee6fb69c"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "print(X.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c06bd8",
      "metadata": {
        "id": "43c06bd8"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener la cantidad total de términos incluidos en la bolsa de palabras:\n",
        "\n",
        "```python\n",
        "❱ print(X.sum())\n",
        "198682\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c301fa",
      "metadata": {
        "id": "84c301fa"
      },
      "source": [
        "## **3. Términos Más Frecuentes**\n",
        "---\n",
        "\n",
        "En esta sección, extraerás los **N términos más frecuentes** del conjunto de datos, utilizando la representación de **bolsa de palabras** y el **vectorizador**.  \n",
        "\n",
        "Para ello, deberás implementar la función **`get_top_n`**, que tomará como entrada la representación de bolsa de palabras, el vectorizador y el número de términos a extraer. Como salida, deberá devolver una lista con los **N términos más frecuentes** en el corpus.  \n",
        "\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- **`X`** (*numpy array*): Representación de bolsa de palabras.  \n",
        "- **`vect`** (*sklearn vectorizer*): Vectorizador previamente entrenado.  \n",
        "- **`n`** (*int*): Número de términos a extraer.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "-  **`words`** (*list of str*): Lista con los **N términos más frecuentes** en el corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cf4d760",
      "metadata": {
        "id": "4cf4d760"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede usar la función `sorted` de `Python` para ordenar términos de acuerdo a una condición.\n",
        "- Puede convertir los datos a un `pd.Series` y usar métodos como `sort_values`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d710de68",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "d710de68"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_top_n:\n",
        "\n",
        "def get_top_n(X, vect, n):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "\n",
        "    words = ...\n",
        "    return words\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fb5c04",
      "metadata": {
        "id": "31fb5c04"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "words = get_top_n(X, vect, 5)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875de364",
      "metadata": {
        "id": "875de364"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 5 palabras más frecuentes del corpus:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['amor', 'vida', 'noche', 'ojos', 'tierra']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f76caa",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "68f76caa"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "words = get_top_n(X, vect, 10)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5fae8c",
      "metadata": {
        "id": "1d5fae8c"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['amor',\n",
        " 'vida',\n",
        " 'noche',\n",
        " 'ojos',\n",
        " 'tierra',\n",
        " 'alma',\n",
        " 'muerte',\n",
        " 'tiempo',\n",
        " 'cielo',\n",
        " 'corazon']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5de9cb",
      "metadata": {
        "id": "2c5de9cb"
      },
      "source": [
        "## **4. Términos Más Frecuentes de un Autor**\n",
        "---\n",
        "\n",
        "En esta sección, filtrarás los $N$ **términos más frecuentes** de un autor específico a partir de la **representación de bolsa de palabras**, el **vectorizador** y una lista con los autores de cada documento.  \n",
        "\n",
        "Para ello, deberás implementar la función **`get_top_n_author`**, que tomará como entrada la representación de bolsa de palabras, el vectorizador, el número de términos a extraer, una lista con los autores de cada documento y el autor a filtrar. Como salida, deberá devolver una lista con los **N términos más frecuentes** en los textos del autor seleccionado.  \n",
        "\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- **`X`** (*numpy array*): Representación de bolsa de palabras.  \n",
        "- **`vect`** (*sklearn vectorizer*): Vectorizador previamente entrenado.  \n",
        "- **`n`** (*int*): Número de términos a extraer.  \n",
        "- **`authors`** (*list of str*): Lista con los autores correspondientes a cada documento.  \n",
        "- **`author_query`** (*str*): Autor sobre el que se debe filtrar.  \n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- **`words`** (*list of str*): Lista con los **N términos más frecuentes** en los textos del autor seleccionado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da359f66",
      "metadata": {
        "id": "da359f66"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Tenga en cuenta que la lista **`authors`** está alineada con la representación de bolsa de palabras **`X`**, es decir, el autor en la posición `5` (**`authors[5]`**) corresponde a la fila `5` de la representación (**`X[5]`**).  \n",
        "- Puede usar **indexación basada en máscaras de `numpy`** para seleccionar los documentos correspondientes al autor indicado.  \n",
        "- Puede reutilizar la función **`get_top_n`**, ya que la tarea es muy similar.  \n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e894f566",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e894f566"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_top_n_author:\n",
        "\n",
        "def get_top_n_author(X, vect, n, authors, author_query):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    words = ...\n",
        "    return words\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb7631ab",
      "metadata": {
        "id": "fb7631ab"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "authors = df.author.to_list()\n",
        "words = get_top_n_author(X, vect, 10, authors, \"Marilina Rébora\")\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "948143d3",
      "metadata": {
        "id": "948143d3"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus en el año 2019:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['dios',\n",
        " 'amor',\n",
        " 'alma',\n",
        " 'senor',\n",
        " 'madre',\n",
        " 'vida',\n",
        " 'quiero',\n",
        " 'tiempo',\n",
        " 'mundo',\n",
        " 'ojos']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f09be4",
      "metadata": {
        "id": "23f09be4"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "authors = df.author.to_list()\n",
        "words = get_top_n_author(X, vect, 10, authors, \"Antonio Colinas\")\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa35f58",
      "metadata": {
        "id": "baa35f58"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus en el año 2020:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['muerte',\n",
        " 'musica',\n",
        " 'ojos',\n",
        " 'vida',\n",
        " 'amor',\n",
        " 'bosque',\n",
        " 'dejadme',\n",
        " 'nieve',\n",
        " 'tiempo',\n",
        " 'gracias']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c7162cc",
      "metadata": {
        "id": "0c7162cc"
      },
      "source": [
        "## **5. Nube de Palabras**\n",
        "---\n",
        "\n",
        "En esta sección, generarás una **nube de palabras** a partir de una **representación de bolsa de palabras**, utilizando un fondo de color blanco.  \n",
        "\n",
        "Para ello, deberás implementar la función **`get_wordcloud`**, que tomará como entrada la representación de bolsa de palabras y un vectorizador, y deberá generar un objeto de tipo **`WordCloud`**.  \n",
        "\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- **`X`** (*numpy array*): Representación de bolsa de palabras.  \n",
        "- **`vect`** (*sklearn vectorizer*): Vectorizador previamente entrenado.  \n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- **`wc`** (*WordCloud*): Objeto de nube de palabras generado a partir de la bolsa de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8853dbb1",
      "metadata": {
        "id": "8853dbb1"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede usar el parámetro `background_color` para especificar el color del fondo de la imagen.\n",
        "- El método `generate_from_frequencies` permite generar la nube de palabras a partir de un diccionario donde las claves son las palabras y los valores son los conteos.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2bc4fb1",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "d2bc4fb1"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_wordcloud:\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def get_wordcloud(X, vect):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    wc = ...\n",
        "    return wc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aa497d4",
      "metadata": {
        "id": "7aa497d4"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "wc = get_wordcloud(X, vect)\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(wc)\n",
        "ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a62b9cb",
      "metadata": {
        "id": "5a62b9cb"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener una imagen similar a la siguiente\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=197H1cdhLwGTba0cBpPwcZ8Wn1qW68dqi\" width=\"50%\">\n",
        "\n",
        "\n",
        "**Nota**: el orden de las palabras puede variar un poco, pero el resultado debería ser equivalente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c1e9e3",
      "metadata": {
        "id": "e3c1e9e3"
      },
      "source": [
        "## **6. Nube de Palabras Por author**\n",
        "---\n",
        "En esta sección, generarás una **nube de palabras** a partir de una **representación de bolsa de palabras**, filtrando los términos correspondientes a un autor específico. La nube de palabras tendrá un fondo de color blanco.  \n",
        "\n",
        "Para ello, deberás implementar la función **`get_wordcloud_author`**, que tomará como entrada la representación de bolsa de palabras, un vectorizador, una lista de autores y un autor específico. Como salida, deberá generar un objeto de tipo **`WordCloud`**.  \n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- **`X`** (*numpy array*): Representación de bolsa de palabras.  \n",
        "- **`vect`** (*sklearn vectorizer*): Vectorizador previamente entrenado.  \n",
        "- **`authors`** (*list of str*): Lista de autores correspondiente a cada documento.  \n",
        "- **`author_query`** (*str*): Autor sobre el cual se filtrarán los términos.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- **`wc`** (*WordCloud*): Objeto de nube de palabras generado a partir de los textos del autor seleccionado.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc4282d",
      "metadata": {
        "id": "1cc4282d"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede reutilizar la función `get_wordcloud`, ya que las tareas son bastante similares.\n",
        "- Debe filtrar las filas de la representación de bolsa de palabras de la misma forma en la que realizó el punto 4.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d2c707",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "b5d2c707"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_wordcloud_author:\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def get_wordcloud_author(X, vect, authors, author_query):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    wc = ...\n",
        "    return wc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb398bf8",
      "metadata": {
        "id": "fb398bf8"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.content.astype(str).apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "authors = df.author.to_list()\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 7))\n",
        "unique_authors = [\"Leopoldo Lugones\", \"Antonio Colinas\", \"Marilina Rébora\"]\n",
        "for i, author in enumerate(unique_authors):\n",
        "    ax = axes[i]\n",
        "    wc = get_wordcloud_author(X, vect, authors, author)\n",
        "    ax.imshow(wc)\n",
        "    ax.set_title(author)\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b4ccf7",
      "metadata": {
        "id": "35b4ccf7"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "La celda anterior debería generar una imagen similar a la siguiente."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Hx5g-_Jp6pmf4jYOV9_5-tg9KUMWZtuQ\" width=\"100%\">"
      ],
      "metadata": {
        "id": "FCYprMN9RC54"
      },
      "id": "FCYprMN9RC54"
    },
    {
      "cell_type": "markdown",
      "id": "ce40476b",
      "metadata": {
        "id": "ce40476b"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://ferestrepoca.github.io/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "title,-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}